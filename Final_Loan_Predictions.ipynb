{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark=SparkSession.builder.appName('Project').getOrCreate()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["df=spark.read.csv(\"/FileStore/tables/train_Loan.csv\",header=True,inferSchema=True)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.sql.functions import isnan, when, count, col"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#Removing nulls in Loan amount \nfrom pyspark.sql.functions import mean, md5\nmean_val= df.select(mean(df['LoanAmount'])).collect()\nmean_la=mean_val[0][0]\ndf=df.na.fill(mean_la,subset=['LoanAmount'])"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#Removing nulls in Loan amount term\nLA_counts = df.groupBy(['Loan_Amount_Term']).count().alias('counts')\nLA_counts.sort(col(\"count\").desc()).show()\nLA_mode=LA_counts.agg({\"count\": \"max\"}).collect()[0][0]\nprint(LA_mode)\ntemp_LA = LA_counts.filter(LA_counts['count']==LA_mode)\ntemp_LA.printSchema()\nLA_mode = temp_LA.select(['Loan_Amount_Term']).collect()[0][0]\ndf=df.na.fill(LA_mode,subset=['Loan_Amount_Term'])"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#removing nulls in gender\nGender_counts = df.groupBy(['Gender']).count().alias('counts')\nGender_counts.sort(col(\"count\").desc()).show()\nGender_mode=Gender_counts.agg({\"count\": \"max\"}).collect()[0][0]\ntemp_Gender = Gender_counts.filter(Gender_counts['count']==Gender_mode)\nGender_mode = temp_Gender.select(['Gender']).collect()[0][0]\ndf=df.na.fill(Gender_mode,subset=['Gender'])"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Removing null in married by mode\nMar_counts = df.groupBy(['Married']).count().alias('counts')\nMar_counts.sort(col(\"count\").desc()).show()\nMar_mode=Mar_counts.agg({\"count\": \"max\"}).collect()[0][0]\ntemp_mar = Mar_counts.filter(Mar_counts['count']==Mar_mode)\nMar_mode = temp_mar.select(['Married']).collect()[0][0]\ndf=df.na.fill(Mar_mode,subset=['Married'])"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#removing null in dependents \nDep_counts = df.groupBy(['Dependents']).count().alias('counts')\nDep_counts.sort(col(\"count\").desc()).show()\nDep_mode=Dep_counts.agg({\"count\": \"max\"}).collect()[0][0]\ntemp_dep = Dep_counts.filter(Dep_counts['count']==Dep_mode)\nDep_mode = temp_dep.select(['Dependents']).collect()[0][0]\ndf=df.na.fill(Dep_mode,subset=['Dependents'])"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#removing null in self employed\nemp_counts = df.groupBy(['Self_Employed']).count().alias('counts')\nemp_counts.sort(col(\"count\").desc()).show()\nemp_mode=emp_counts.agg({\"count\": \"max\"}).collect()[0][0]\ntemp_emp = emp_counts.filter(emp_counts['count']==emp_mode)\nemp_mode = temp_emp.select(['Self_Employed']).collect()[0][0]\ndf=df.na.fill(emp_mode,subset=['Self_Employed'])"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#removing null in credit history\nch_counts = df.groupBy(['Credit_History']).count().alias('counts')\nch_counts.sort(col(\"count\").desc()).show()\nch_mode=ch_counts.agg({\"count\": \"max\"}).collect()[0][0]\ntemp_ch = ch_counts.filter(ch_counts['count']==ch_mode)\nch_mode = temp_ch.select(['Credit_History']).collect()[0][0]\ndf=df.na.fill(ch_mode,subset=['Credit_History'])"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["\ndf.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#Adding new feature total income\ndf_with_totalincome = df.withColumn('total_income', df['ApplicantIncome']+df['CoapplicantIncome'])\ndf_with_totalincome.show()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#Adding new feature ratio of total income to loan amount\ndf_with_ratio = df_with_totalincome.withColumn('ratio', df_with_totalincome['total_income']/df_with_totalincome['LoanAmount'])\ndf_with_ratio.show()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["#final dataset after removing nulls\nselected_data = df_with_ratio.select('Gender',\n 'Married',\n 'Dependents',\n 'Education',\n 'Self_Employed',\n 'ApplicantIncome',\n 'CoapplicantIncome',\n 'LoanAmount',\n 'Loan_Amount_Term',\n 'Credit_History',\n 'Property_Area',\n 'Loan_Status','total_income','ratio')\nselected_data.show()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.linalg import Vector\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer\n"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["final = selected_data.where(selected_data.Gender.isNotNull())\nfinal = final.where(final.Married.isNotNull())\nfinal = final.where(final.Dependents.isNotNull())\nfinal = final.where(final.Education.isNotNull())\nfinal = final.where(final.Self_Employed.isNotNull())\nfinal.show()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["#dummy coding gender Male =0 ; Female =1\ngen_indexer = StringIndexer(inputCol=\"Gender\", outputCol=\"_Gender_index\" )\ngen_model = gen_indexer.fit(final)\ngen_indexed = gen_model.transform(final)\ngen_encoder = OneHotEncoder( inputCol=\"_Gender_index\", outputCol=\"_Gender_vec\")\nfinal1 = gen_encoder.transform(gen_indexed)\nfinal1.show()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["#Dummy coding Married Yes =0, No =1\nmar_indexer = StringIndexer(inputCol=\"Married\", outputCol=\"_Married_index\" )\nmar_model = mar_indexer.fit(final1)\nmar_indexed = mar_model.transform(final1)\nmar_encoder = OneHotEncoder( inputCol=\"_Married_index\", outputCol=\"_Married_vec\")\nfinal2 = mar_encoder.transform(mar_indexed)\nfinal2.show()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["#Dummy coding Dependent\ndep_indexer = StringIndexer(inputCol=\"Dependents\", outputCol=\"_Dependents_index\" )\ndep_model = dep_indexer.fit(final2)\ndep_indexed = dep_model.transform(final2)\ndep_encoder = OneHotEncoder( inputCol=\"_Dependents_index\", outputCol=\"_Dependents_vec\")\nfinal3 = dep_encoder.transform(dep_indexed)\nfinal3.show()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["#Dummy coding Education graduate =0 ; not graduate =1\nedu_indexer = StringIndexer(inputCol=\"Education\", outputCol=\"_Education_index\" )\nedu_model = edu_indexer.fit(final3)\nedu_indexed = edu_model.transform(final3)\nedu_encoder = OneHotEncoder( inputCol=\"_Education_index\", outputCol=\"_Education_vec\")\nfinal4 = edu_encoder.transform(edu_indexed)\nfinal4.show()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#Dummy coding Self employed No =0 ; Yes= 1\nemp_indexer = StringIndexer(inputCol=\"Self_Employed\", outputCol=\"_Self_Employed_index\" )\nemp_model = emp_indexer.fit(final4)\nemp_indexed = emp_model.transform(final4)\nemp_encoder = OneHotEncoder( inputCol=\"_Self_Employed_index\", outputCol=\"_Self_Employed_vec\")\nfinal5 = emp_encoder.transform(emp_indexed)\nfinal5.show()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["#Dummy coding Property Area Urban =1; Rural =0;semiurban =2\narea_indexer = StringIndexer(inputCol=\"Property_Area\", outputCol=\"_Property_Area_index\" )\narea_model = area_indexer.fit(final5)\narea_indexed = area_model.transform(final5)\narea_encoder = OneHotEncoder( inputCol=\"_Property_Area_index\", outputCol=\"_Property_Area_vec\")\nfinal6 = area_encoder.transform(area_indexed)\nfinal6.show()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["#Dummy coding Loan Status yes =0 ; No = 1\nloan_indexer = StringIndexer(inputCol=\"Loan_Status\", outputCol=\"_Loan_Status_index\" )\nloan_model = loan_indexer.fit(final6)\nloan_indexed = loan_model.transform(final6)\nloan_encoder = OneHotEncoder( inputCol=\"_Loan_Status_index\", outputCol=\"_Loan_Status_vec\")\nfinal7 = loan_encoder.transform(loan_indexed)\nfinal7.show()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["final7.columns"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["assembler = VectorAssembler(inputCols = ['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Credit_History','total_income','ratio',\n '_Gender_vec', \n '_Married_vec', \n '_Dependents_vec','_Education_vec','_Self_Employed_vec','_Property_Area_vec'], outputCol = 'features')"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["final8 = assembler.transform(final7)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["final8.show()"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["new_final= final8.select(\"features\",\"_Loan_Status_index\")\nnew_final.show()"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["train_data, test_data = new_final.randomSplit([0.7, 0.3])"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["lr = LogisticRegression(featuresCol = 'features', labelCol = '_Loan_Status_index', maxIter = 10)\ntrain_data.printSchema()\nlr_Model = lr.fit(train_data)\npred = lr_Model.transform(test_data)\npred.show()"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["my_eval = BinaryClassificationEvaluator(labelCol = '_Loan_Status_index')"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["my_eval.evaluate(pred)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["#**** Decision Tree\nfrom pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier\ndtc = DecisionTreeClassifier()\ndtc = DecisionTreeClassifier(labelCol = \"_Loan_Status_index\", featuresCol = \"features\")"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["dtc_model = dtc.fit(train_data)\ndtc_pred = dtc_model.transform(test_data)\ndtc_pred.show()"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["my_eval2 = BinaryClassificationEvaluator(labelCol = '_Loan_Status_index')"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["my_eval2.evaluate(dtc_pred)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["#Random forest\nrfc = RandomForestClassifier()\nrfc = RandomForestClassifier(labelCol = \"_Loan_Status_index\", featuresCol = \"features\")\nrfc_model = rfc.fit(train_data)\nrfc_pred = rfc_model.transform(test_data)\nrfc_pred.show()"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["my_eval3 = BinaryClassificationEvaluator(labelCol = '_Loan_Status_index')\nmy_eval3.evaluate(rfc_pred)"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["#Gradient Boosting\ngbc = GBTClassifier\ngbc = GBTClassifier(labelCol = \"_Loan_Status_index\", featuresCol = \"features\")\ngbc_model = gbc.fit(train_data)\ngbc_pred = gbc_model.transform(test_data)\ngbc_pred.show()"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["my_eval4 = BinaryClassificationEvaluator(labelCol = '_Loan_Status_index')\nmy_eval4.evaluate(gbc_pred)"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["#Uploading the test dataset\ntest=spark.read.csv(\"/FileStore/tables/test.csv\",header=True,inferSchema=True)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["test.show()"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["test.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in test.columns]).show()"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["#removing nulls in gender\nGender_counts = test.groupBy(['Gender']).count().alias('counts')\nGender_counts.sort(col(\"count\").desc()).show()\nGender_mode=Gender_counts.agg({\"count\": \"max\"}).collect()[0][0]\ntemp_Gender = Gender_counts.filter(Gender_counts['count']==Gender_mode)\nGender_mode = temp_Gender.select(['Gender']).collect()[0][0]\ntest=test.na.fill(Gender_mode,subset=['Gender'])"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["#removing null in self employed\nemp_counts = test.groupBy(['Self_Employed']).count().alias('counts')\nemp_counts.sort(col(\"count\").desc()).show()\nemp_mode=emp_counts.agg({\"count\": \"max\"}).collect()[0][0]\ntemp_emp = emp_counts.filter(emp_counts['count']==emp_mode)\nemp_mode = temp_emp.select(['Self_Employed']).collect()[0][0]\ntest=test.na.fill(emp_mode,subset=['Self_Employed'])"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["#removing null in dependents \nDep_counts = test.groupBy(['Dependents']).count().alias('counts')\nDep_counts.sort(col(\"count\").desc()).show()\nDep_mode=Dep_counts.agg({\"count\": \"max\"}).collect()[0][0]\ntemp_dep = Dep_counts.filter(Dep_counts['count']==Dep_mode)\nDep_mode = temp_dep.select(['Dependents']).collect()[0][0]\ntest=test.na.fill(Dep_mode,subset=['Dependents'])"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["#removing null in credit history\nch_counts = test.groupBy(['Credit_History']).count().alias('counts')\nch_counts.sort(col(\"count\").desc()).show()\nch_mode=ch_counts.agg({\"count\": \"max\"}).collect()[0][0]\ntemp_ch = ch_counts.filter(ch_counts['count']==ch_mode)\nch_mode = temp_ch.select(['Credit_History']).collect()[0][0]\ntest=test.na.fill(ch_mode,subset=['Credit_History'])"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":["#Removing nulls in Loan amount \nfrom pyspark.sql.functions import mean, md5\nmean_val= test.select(mean(test['LoanAmount'])).collect()\nmean_la=mean_val[0][0]\ntest=test.na.fill(mean_la,subset=['LoanAmount'])\n"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["#removing null in loan amount term\nch_counts = test.groupBy(['Loan_Amount_Term']).count().alias('counts')\nch_counts.sort(col(\"count\").desc()).show()\nch_mode=ch_counts.agg({\"count\": \"max\"}).collect()[0][0]\ntemp_ch = ch_counts.filter(ch_counts['count']==ch_mode)\nch_mode = temp_ch.select(['Loan_Amount_Term']).collect()[0][0]\ntest=test.na.fill(ch_mode,subset=['Loan_Amount_Term'])"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["test_with_totalincome = test.withColumn('total_income', test['ApplicantIncome']+test['CoapplicantIncome'])\ntest_with_totalincome.show()"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["test_with_ratio = test_with_totalincome.withColumn('ratio', test_with_totalincome['total_income']/test_with_totalincome['LoanAmount'])\ntest_with_ratio.show()"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["#final dataset after removing nulls\ntest_final = test_with_ratio.select('Gender',\n 'Married',\n 'Dependents',\n 'Education',\n 'Self_Employed',\n 'ApplicantIncome',\n 'CoapplicantIncome',\n 'LoanAmount',\n 'Loan_Amount_Term',\n 'Credit_History',\n 'Property_Area',\n'total_income','ratio')\ntest_final.show()"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["#Encoding features of test dataset\ngen_indexed = gen_model.transform(test_final)\ntest_final1= gen_encoder.transform(gen_indexed)\nmar_indexed = mar_model.transform(test_final1)\ntest_final2 = mar_encoder.transform(mar_indexed)\ndep_indexed = dep_model.transform(test_final2)\ntest_final3 = dep_encoder.transform(dep_indexed)\nedu_indexed = edu_model.transform(test_final3)\ntest_final4 = edu_encoder.transform(edu_indexed)\nemp_indexed = emp_model.transform(test_final4)\ntest_final5 = emp_encoder.transform(emp_indexed)\narea_indexed = area_model.transform(test_final5)\ntest_final6 = area_encoder.transform(area_indexed)\ntest_final6.columns"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":["#Assembling columns and creating feature column for test dataset\ntest_final7=assembler.transform(test_final6)"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["test_final7.show()"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["#Building model on entire training dataset(without splitting)\n#Random forest\nrfc = RandomForestClassifier()\nrfc = RandomForestClassifier(labelCol = \"_Loan_Status_index\", featuresCol = \"features\")\nrfc_model = rfc.fit(new_final)\nrfc_pred = rfc_model.transform(test_final7)\nrfc_pred.show()"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"code","source":["#final predictions on test data\npredictions_dataset = rfc_pred.select('features','rawPrediction','probability','prediction')\npredictions_dataset.show()"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":["df1=rfc_pred.filter(rfc_pred['prediction']==\"1\").describe()"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["df1.show()"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["df1.select('summary','ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','total_income','ratio').show()"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":65}],"metadata":{"name":"model with updates","notebookId":475508854023478},"nbformat":4,"nbformat_minor":0}
